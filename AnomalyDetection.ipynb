{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnomalyDetection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPSnM13gPI_a"
      },
      "source": [
        "imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAxpNnrGMPFw"
      },
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from sklearn.externals import joblib\r\n",
        "import seaborn as sns\r\n",
        "sns.set(color_codes=True)\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from numpy.random import seed\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzH4Hj4t4_hi"
      },
      "source": [
        "from keras.layers import Input, Dense, LSTM, TimeDistributed, RepeatVector\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from keras import regularizers\r\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kgTDKawexUe"
      },
      "source": [
        "Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6FKn7Qo6kph"
      },
      "source": [
        "from sklearn.cluster import KMeans\r\n",
        "from sklearn.cluster import DBSCAN\r\n",
        "from sklearn.ensemble import IsolationForest\r\n",
        "import numpy as np\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siVzTDdx8KEv"
      },
      "source": [
        "columns=['Bearing 1','Bearing 2','Bearing 3','Bearing 4']\r\n",
        "directory='dataset/'\r\n",
        "sensor_data=pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImSEVA9a8c1q"
      },
      "source": [
        "for file in os.listdir(directory):\r\n",
        "  dataset= pd.read_csv(os.path.join(directory,file),sep='\\t')\r\n",
        "  data_mean=pd.DataFrame(np.array(dataset.abs().mean()).reshape(1,4))\r\n",
        "  data_mean.index=[file]\r\n",
        "  sensor_data=sensor_data.append(data_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oDJxwgP9Pwi"
      },
      "source": [
        "sensor_data.columns=columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGHvp0GT-OCO"
      },
      "source": [
        "sensor_data_index=pd.to_datatime(sensor_data.index,format='%Y.%m.%d.%H.%M.%S.)\r\n",
        "sensor_data=sensor_data.sort_index()\r\n",
        "sensor_data.to_csv('Averaged_BearingTest_Dataset.csv')\r\n",
        "print('Dataset shape:', sensor_data.shape)\r\n",
        "sensor_data.head()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbFn8Aj5PXdx"
      },
      "source": [
        "print healthy sensor data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWkxwEwd_GAW"
      },
      "source": [
        "fig,ax= plt.subplots(figsize(15,8),dpi=80)\r\n",
        "ax.plot(sensor_data[ columns[0] ], label=columns[0],color='blue',animated= True,linewidth=1)\r\n",
        "ax.plot(sensor_data[ columns[1] ], label=columns[1],color='red',animated= True,linewidth=1)\r\n",
        "ax.plot(sensor_data[ columns[2] ], label=columns[2],color='green',animated= True,linewidth=1)\r\n",
        "ax.plot(sensor_data[ columns[3] ], label=columns[3],color='black',animated= True,linewidth=1)\r\n",
        "plt.legend(loc='lower left')\r\n",
        "ax.set_title('Bearing Train Data',fontsize=16)\r\n",
        "plt.show()\r\n",
        "fig.savefig('Bearing Train Data')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ2GTguaPhMi"
      },
      "source": [
        "divide dataset to train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USGpctZAALzl"
      },
      "source": [
        "train_data=sensor_data['2004-02-12 10:52:39': '2004-02-15 12:52:39']\r\n",
        "test_data=sensor_data['2004-02-15 12:52:39':]\r\n",
        "print(\"Training dataset shape:\", train_data.shape)\r\n",
        "print(\"Test dataset shape:\", test_data.shape)\r\n",
        "print(\"Training to test ratio:\", train_data.shape[0]/ sensor_data.shape[0], test_data.shape[0]/ sensor_data.shape[0])\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyYEq65OPons"
      },
      "source": [
        "print healthy sensor data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fYVJLvFBIxW"
      },
      "source": [
        "fig,ax=plt.subplots(figsize(15,8))\r\n",
        "ax.plot(train_data[columns[0]], label=columns[0], color='blue', animated=True,linewidth=1)\r\n",
        "ax.plot(train_data[columns[1]], label=columns[1], color='red', animated=True,linewidth=1)\r\n",
        "ax.plot(train_data[columns[2]], label=columns[2], color='green', animated=True,linewidth=1)\r\n",
        "ax.plot(train_data[columns[3]], label=columns[3], color='black', animated=True,linewidth=1)\r\n",
        "plt.legends(loc='lower_left')\r\n",
        "ax.set_title('Bearing Train Data', fontsize= 16)\r\n",
        "plt.show()\r\n",
        "fig.savefig('Bearing Train Data')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zFulfdPPvcY"
      },
      "source": [
        "transform data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCwX_q7mCBAD"
      },
      "source": [
        "fft= np.fft.fft(sensor_data)\r\n",
        "train_fft=np.fft.fft(train_data)\r\n",
        "test_fft=np.fft.fft(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjsBDbSDQEXI"
      },
      "source": [
        "print healthy sensor frequency data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op561mCERUs8"
      },
      "source": [
        "fig,(ax1,ax2,ax3)=plt.subplots(3,1,figsize=(20,15),dpi=80)\r\n",
        "ax1.plot(train_fft[:0].real, label=columns[0], color='blue', animated=True, linewidth=1)\r\n",
        "ax1.plot(train_fft[:1].real, label=columns[1], color='red', animated=True, linewidth=1)\r\n",
        "ax1.plot(train_fft[:2].real, label=columns[2], color='green', animated=True, linewidth=1)\r\n",
        "ax1.plot(train_fft[:3].real, label=columns[3], color='black', animated=True, linewidth=1)\r\n",
        "plt.legend(loc='lower left')\r\n",
        "ax1.set_title('Bearing Sensor Train Frequency Data', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lib8PHzVPGd-"
      },
      "source": [
        "print degrading sensor frequency data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkBtUrOZe9HU"
      },
      "source": [
        "ax2.plot(test_fft[:,0].real, label=columns[0], color='blue', animated= True, linewidth=1)\r\n",
        "ax2.plot(test_fft[:,1].real, label=columns[1], color='red', animated= True, linewidth=1)\r\n",
        "ax2.plot(test_fft[:,2].real, label=columns[2], color='green', animated= True, linewidth=1)\r\n",
        "ax2.plot(test_fft[:,3].real, label=columns[3], color='black', animated= True, linewidth=1)\r\n",
        "plt.legend(loc='lower left')\r\n",
        "ax2.set_titles('Bearing Sensor Test Frequency Data', fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XsQeL-of3OX"
      },
      "source": [
        "print frequency of whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GzlN5vFgBGf"
      },
      "source": [
        "ax3.plot(fft[:,0].real, label=columns[0], color='blue', animated= True, linewidth=1)\r\n",
        "ax3.plot(fft[:,1].real, label=columns[1], color='red', animated= True, linewidth=1)\r\n",
        "ax3.plot(fft[:,2].real, label=columns[2], color='green', animated= True, linewidth=1)\r\n",
        "ax3.plot(fft[:,3].real, label=columns[3], color='black', animated= True, linewidth=1)\r\n",
        "plt.legend(loc='lower left')\r\n",
        "ax3.set_title('Bearing Sensor All Frequency Data', fontsize=16)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kPeDZQJgm9n"
      },
      "source": [
        "fig.savefig('Frequency of Dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CmgEbshgt0M"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk-3NKMugwkD"
      },
      "source": [
        "normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVdQs0dZgspK"
      },
      "source": [
        "scaler= preprocessing.MinMaxScaler()\r\n",
        "scaled_train_data=scaler.fit_transform(train_data)\r\n",
        "scaled_test_data=scaler.transform(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E14lCa-RhGz2"
      },
      "source": [
        "scaled_train_array = scaled_train_data.reshape(scaled_train_data.shape[0], 1, scaled_train_data.shape[1])\r\n",
        "print('Training data shape: ', scaled_train_array.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvOZvds5ke9p"
      },
      "source": [
        "Autoencoder method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ByF72Tiki9s"
      },
      "source": [
        "create the autoencoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5FuEoBVkV7E"
      },
      "source": [
        "inputs= Input(shape=(scaled_train_array.shape[1], scaled_train_array.shape[2]))\r\n",
        "LSTM1 = LSTM(16, activation='relu', return_sequences= True, kernel_regularizer=regularizers.12(0.00))(inputs)\r\n",
        "LSTM2 = LSTM(4, activation='relu', return_sequences= False)(LSTM1)\r\n",
        "LSTM3 = RepeatVector(scaled_train_array.shape[1])(LSTM2)\r\n",
        "LSTM4 = LSTM(4, activation='relu', return_sequences= True)(LSTM3)\r\n",
        "LSTM5 = LSTM(16, activation='relu', return_sequences= True)(LSTM4)\r\n",
        "out= TimeDistributed(Dense(scaled_train_array.shape[2]))(LSTM5)\r\n",
        "model= Model(inputs=inputsi outputs=out)\r\n",
        "model.compile(optimizer='adam', loss='mae')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA0U3_mZnwx9"
      },
      "source": [
        "fit the model to the data\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slTUvoPgn0ee"
      },
      "source": [
        "history = model.fit(scaled_train_array, scaled_train_array, epochs=100, batch_size=10, validation_split=0.05).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJTcBPCVoIzy"
      },
      "source": [
        "plot the training losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUk9Y2WZoNf2"
      },
      "source": [
        "fig, ax= plt. subplots(figsize=(15,8), dpi=80)\r\n",
        "ax.plot(history['loss'], 'b', label='Train', linewidth=2)\r\n",
        "ax.plot(history['val_loss'], 'r', label='Validation', linewidth=2)\r\n",
        "ax.set_title('Autoencoder Training Loss', fontsize= 16)\r\n",
        "ax.set_ylabel('Loss')\r\n",
        "ax.legend(loc='upper right')\r\n",
        "plt.show()\r\n",
        "fig.savefig('Training history')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS9thGKopFvP"
      },
      "source": [
        "loss distribution for thresold estimation\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9DGpKiApLgw"
      },
      "source": [
        "train_pred= model.predict(scaled_train_array)\r\n",
        "train_pred= train_pred.reshape(train_pred.shape[0], train_pred.shape[2])\r\n",
        "train_pred= pd.DataFrame(train_pred, columns= columns)\r\n",
        "train_pred.index=train_data.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt5mU3MYp7_p"
      },
      "source": [
        "scored= pd.DataFrame(index=train_data.index)\r\n",
        "scored['Loss']= np.mean(np.abs(train_pred - scaled_train_array.reshape(scaled_train_array.shape[0], scaled_train_array.shape[2])), axis=1)\r\n",
        "plt.figure(figsize=(16,9), dpi=80)\r\n",
        "plt.title('Train Set Loss Distribution', fontsize=16)\r\n",
        "sns.distplot(scored['Loss'], bins=20, kde=True, color='blue');\r\n",
        "plt.xlim([0.0,.5])\r\n",
        "plt.savefig('Train Set Loss Distribution')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wByocX1Hrd7B"
      },
      "source": [
        "calculate the loss on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBHTw2DArhp-"
      },
      "source": [
        "test_pred= model.predict(scaled_test_array)\r\n",
        "test_pred=test_pred.reshape(test_pred.shape[0], test_pred.shape[2])\r\n",
        "test_pred= pd.DataFrame(trst_pred, columns=columns)\r\n",
        "test_pred.index= test_data.index\r\n",
        "scored_test=pd.DataFrame(index=test_data.index)\r\n",
        "scored_test['Loss']= np.mean(np.abs(test_pred - scaled_test_array.reshape(scaled_test_array.shape[0], scaled_test_array.shape[2])), axis= 1)\r\n",
        "scored_test['Threshold']= 0.275\r\n",
        "scored_test['Anomaly']= scored_test['Loss'] > scored_test['Threshold']\r\n",
        "scored_test.head()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVwYx2w2tTrr"
      },
      "source": [
        "plot metrics for the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CPPrv2YtYsj"
      },
      "source": [
        "pred_train= model.predict(scaled_train_array)\r\n",
        "pred_train= pred_train.reshape(pred_train.shape[0], pred_train.shape[2])\r\n",
        "pred_train= pd.DataFrame(pred_train, columns=columns)\r\n",
        "pred_train.index= train_data.index\r\n",
        "\r\n",
        "scored_train['Loss']= np.mean(np.abs(pred_train - scaled_train_array.reshape(scaled_train_array[0], scaled_train_array[2])), axis=1)\r\n",
        "scored_train['Anomaly'] =scored_train['Loss'] > scored_train['Threshold'] \r\n",
        "scored= pd.concat([scored_train, scored_test])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D19Vi54hu4M6"
      },
      "source": [
        "plot bearing failure time plot\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bnYuvnmu9F0"
      },
      "source": [
        "scored.plot(logy= True, figsize= (16,9), ylim=[1e-2,1e2], color=['blue','red'])\r\n",
        "plt.title('Bearing Failure', fontsize= 16)\r\n",
        "plt.savefig('Autoencoder Dataset Loss')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v73_HLPRvbur"
      },
      "source": [
        "K-means\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw32mOvnvgYL"
      },
      "source": [
        "perform PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2m3jrxevety"
      },
      "source": [
        "pca=PCA()\r\n",
        "pca.fit(scaled_train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2m4l7BBvoXM"
      },
      "source": [
        "percentage variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9t4bsCMvqP5"
      },
      "source": [
        "per_var= np.round(pca.explained_variance_ratio_*100, decimals=1)\r\n",
        "labels=[str(x) for x in range(1, len(per_var)+1)]\r\n",
        "cum_var_explained= np.cumsum(per_var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzb9fr_O71Xg"
      },
      "source": [
        "plot percentage variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKOApM1574aI"
      },
      "source": [
        "fig(ax1, ax2, ax3)= plt.subplots(1, 3, figsize=(25,8))\r\n",
        "ax1.bar(x=range(1, per_var.shape[0]+1), height= per_var, tick_label=labels)\r\n",
        "ax1.set_xlabel('Principal Component')\r\n",
        "ax1.set_ylabel('Percentage of Explained Variable')\r\n",
        "ax1.set_title('Screen plot', fontsize=16)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dglY-FOI8lyb"
      },
      "source": [
        "plot the pca spectrum\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8yBZhAY8o1S"
      },
      "source": [
        "ax2.plot(cum_var_explained, linewidth=2)\r\n",
        "ax2.axis('tight')\r\n",
        "ax2.set_xlabel('Number of Principal Component')\r\n",
        "ax2.set_ylabel('Cumulative Explained Variable')\r\n",
        "ax2.set_title('Cumulative Variance Explained', fontsize=16)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3PA4rlK9Rpa"
      },
      "source": [
        "pca plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANAh8aDF9Qsz"
      },
      "source": [
        "pca= PCA(n_components=2)\r\n",
        "pca.fit(scaled_train_data)\r\n",
        "pca_train_data= pca.transform(scaled_train_data)\r\n",
        "pca_test_data= pca.transform(scaled_test_data)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7wuEqNX9nTs"
      },
      "source": [
        "labels=['PC' + str(x) for x in range(1, pca_train_data.shape[1]+1)]\r\n",
        "pca_train_df= pd.DataFrame(pca_train_data, columns=labels)\r\n",
        "pca_train_df.index=train_data.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO20psGT-GOI"
      },
      "source": [
        "ax3.scatter(pca_train_df.PC1, pca_train_df.PC2)\r\n",
        "ax3.set_xlabel('PC1 - {0}%'.format(per_var[0]))\r\n",
        "ax3.set_ylabel('PC1 - {0}%'.format(per_var[1]))\r\n",
        "ax3.set_title('Data distribution after PCA', fontsize=16)\r\n",
        "plt.show()\r\n",
        "fig.savefig('PCA information')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj_SDLM_-0ZQ"
      },
      "source": [
        "run the k means algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naUdf3mk-zfq"
      },
      "source": [
        "kmeans= KMeans(n_clusters=2).fit(pca_train_df)\r\n",
        "kmeans.predict(pca_test_data)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMEKKo-O_Hmx"
      },
      "source": [
        "Plot the decision boundary. For that we will assign a color to each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL-ToHNu_K0-"
      },
      "source": [
        "merged_array=sensor_data.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFdW23V5_ZAM"
      },
      "source": [
        "h=.02\r\n",
        "x_min, x_max= pca_train_data[:,0].min()-1, pca_train_data[:,0].max()+1\r\n",
        "y_min, y_max= pca_train_data[:,1].min()-1, pca_train_data[:,1].max()+1\r\n",
        "xx, yy= np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWRISTII_79H"
      },
      "source": [
        "obtain labels for each point in mesh. Use last trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNvN6yncAFmz"
      },
      "source": [
        "Z= kmeans.predict(np.c_[xx.ravel(), yy.ravel()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESirhSbeAPru"
      },
      "source": [
        "put the result into a color plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSC9x-S-AOjR"
      },
      "source": [
        "Z=Z.reshape(xx.shape)\r\n",
        "centroids= kmeans.cluster_centers_\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWXoHSl7AdHK"
      },
      "source": [
        "fig= plt.figure(figsize=(15,8), dpi=80)\r\n",
        "plt.imshow(Z, interpolation='nearest', extent=(xx.min(), xx.max(), yy.min(), yy.max()), cmap=plt.cm.Paired, aspect='auto', origin= 'lower')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jcACSitA9o_"
      },
      "source": [
        "b1= plt.plot(pca_train_data[:,0], pca_train_data[:,1], 'k.', markersize=2)\r\n",
        "b2= plt.plot(pca_train_data[:,0], pca_train_data[:,1], 'k.', markersize=2)\r\n",
        "plt.scatter(centroids[:,0], centroids[:,1], marker='x', s=169, linewidths=3, color='w', zorder=10)\r\n",
        "plt.title('K-means clustering')\r\n",
        "plt.xlim(x_min, x_max)\r\n",
        "plt.ylim(y_min, y_max)\r\n",
        "plt.xticks(())\r\n",
        "plt.yticks(())\r\n",
        "plt.xlim((-1,1))\r\n",
        "plt.ylim((-1,1))\r\n",
        "plt.show()\r\n",
        "fig.savefig('K-means clustering')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUhax0ACCPmF"
      },
      "source": [
        "DBSCAN clustering method "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5j12aKwCOvJ"
      },
      "source": [
        "sensor_array= sensor_data.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44M5J8m5ObB6"
      },
      "source": [
        "the parameter eps and min_samples were tuned experimentally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMc-IBYzOU_C"
      },
      "source": [
        "dbscan= DBSCAN(eps=0.05, min_samples=10).fit(sensor_array)\r\n",
        "core_samples_mask=np.zeros_like(dbscan.labels_,dtype=bool)\r\n",
        "core_samples_mask[dbscan.core_sample_indices_]=True\r\n",
        "labels=dbscan.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI43Qo9nPGJ8"
      },
      "source": [
        "number of clusters in labels, ignoring noise if present."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP4-g61mPMzj"
      },
      "source": [
        "n_clusters_=len(set(dbscan.labels_)) - (1 if -1 in dbscan.labels_ else 0)\r\n",
        "n_noise_= list(dbscan.labels_).count(-1)\r\n",
        "print('Estimated number of clusters: %d' %n_clusters_)\r\n",
        "print('Estimated number of clusters: %d' %n_noise_)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzn0MFl3P-uc"
      },
      "source": [
        "unique_labels=set(labels)\r\n",
        "colors=[plt.cm.Spectral(each) for each in np.linspace(0,1,len(unique_labels))]\r\n",
        "fig= plt.figure(1, figsize=(15,8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XpWgUWbQXe3"
      },
      "source": [
        "for k, col in zip(unique_labels,colors):\r\n",
        "  if k==-1:\r\n",
        "    #Black used for noise\r\n",
        "    col=[0,0,0,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_toY8yHQpM2"
      },
      "source": [
        "class_member_mask= (labels==k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtRoW03UQwGy"
      },
      "source": [
        "xy = sensor_array[class_member_mask & core_samples_mask]\r\n",
        "plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col), markeredgecolor='k', markersize=6)\r\n",
        "plt.title('DBSCAN clustering')\r\n",
        "plt.show()\r\n",
        "fig.savefig('DBSCAN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5S662TxRdxW"
      },
      "source": [
        "Isolation Forest Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKzUVd3VRgxP"
      },
      "source": [
        "iso_forest= IsolationForest(n_estimators=2)\r\n",
        "iso_forest.fit(pca_train_data)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTVmg_QmRsLn"
      },
      "source": [
        "find if data is an outlier or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxfjQqyCRwdo"
      },
      "source": [
        "train_iso_indexes= iso_forest.predict(pca_train_data)\r\n",
        "test_iso_indexes= iso_forest.predict(pca_test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzdpuCvNSCYp"
      },
      "source": [
        "select outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kOk2kmuSElY"
      },
      "source": [
        "train_neg_preds=pca_train_data[train_iso_indexes==1]\r\n",
        "test_neg_preds=pca_test_data[test_iso_indexes==1]\r\n",
        "outliers = np.concatenate((pca_train_data[train_iso_indexes == -1], pca_test_data[test_iso_indexes == -1]), axis=0)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psNma5UeS01b"
      },
      "source": [
        "plot isolation forest prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-DrIN_rS4gp"
      },
      "source": [
        "xx, yy=np.meshgrid(np.linspace(-5, 5, 50), np.linspace(-5, 5, 50))\r\n",
        "Z= iso_forest.decision_function(np.c_[xx.ravel(), yy.ravel()])\r\n",
        "Z= Z.reshape(xx.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70zvc51ATXxf"
      },
      "source": [
        "fig=plt.figure(1, figsize=(15, 8))\r\n",
        "plt.title('Isolation Forest')\r\n",
        "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues_r)\r\n",
        "b1= plt.scatter(train_neg_preds[:, 0], train_neg_preds[:, 1], c='white', s=20, edgecolor='k')\r\n",
        "b2= plt.scatter(test_neg_preds[:, 0], test_neg_preds[:, 1], c='green', s=20, edgecolor='k')\r\n",
        "c= plt.scatter(outliers[:, 0], outliers[:, 1], c='red', s=20, edgecolor='k')\r\n",
        "plt.axis('tight')\r\n",
        "plt.xlim((-5, 5))\r\n",
        "plt.ylim((-5, 5))\r\n",
        "plt.legend([b1, b2, c], ['training observations: ' +str(len(train_neg_preds)), 'new regular observations: ' +str(len(test_neg_preds)), 'new abnormal observations' +str(len(outliers))], loc='upper left')\r\n",
        "plt.show()\r\n",
        "fig.savefig('Isolation Forest')\r\n",
        "print('Number of outliers:', len(outliers))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDmBtp1AVwvR"
      },
      "source": [
        "def MD_detectOutliers(dist, verbose=False):\r\n",
        "  outliers=[]\r\n",
        "  for i in range(len(dist)):\r\n",
        "    if dist[i]>=(np.mean(dist)*3):\r\n",
        "      outliers.append(i)\r\n",
        "  return np.array(outliers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdhPQZVgWSlT"
      },
      "source": [
        "def MD_threshold(dist):\r\n",
        "  return np.mean(dist)*3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHLzcFXeh_RF"
      },
      "source": [
        "def Mahalanobis_Dist(inv_cov, mean, data):\r\n",
        "  inv_covariance_matrix=inv_cov\r\n",
        "  temp= data-mean\r\n",
        "  mah_dist=[]\r\n",
        "  for i in range(len(temp)):\r\n",
        "    mah_dist.append(np.sqrt(temp[i].dot(inv_covariance_matrix).dot(temp[i])))\r\n",
        "  return np.array(mah_dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dMZufGtipcx"
      },
      "source": [
        "Mahalanobis Distance method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W852doF-isoH"
      },
      "source": [
        "pca_data_train=np.array(pca_train_df.values)\r\n",
        "pca_data_test=np.array(pca_test_df.values)\r\n",
        "mean= pca_data_train.mean(axis=0)\r\n",
        "cov_matrix=np.cov(pca_data_train, rowvar=False)\r\n",
        "inv_cov_matrix=np.linalg.inv(cov_matrix)\r\n",
        "dist_train= Mahalanobis_Dist(inv_cov_matrix, mean, pca_data_train)\r\n",
        "dist_test= Mahalanobis_Dist(inv_cov_matrix, mean, pca_data_test)\r\n",
        "threshold= MD_threshold(dist_train)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCYw6_PyjvG4"
      },
      "source": [
        "fig= plt.figure(figsize=(15, 8))\r\n",
        "sns.distplot(dist_train, bins=10, kde=True, color='green');\r\n",
        "plt.xlim([0.0,5])\r\n",
        "plt.title('Mahalanobis dist', fontsize=16)\r\n",
        "fig.savefig('Mahalanobis dist')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0p6_8yrkNrv"
      },
      "source": [
        "predict anomaly using Mahalanobis distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkrp61LDkRgk"
      },
      "source": [
        "train_anomaly= pd.DataFrame()\r\n",
        "train_anomaly['Dist']=dist_train\r\n",
        "train_anomaly['Threshold']= threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcqMflu5kqTY"
      },
      "source": [
        "If distance > threshold => anomalies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctKfP9AAkwO_"
      },
      "source": [
        "anomalies['Anomaly']= anomalies['Dist'] > anomalies['Threshold']\r\n",
        "anomalies.index=pca_test_df.index\r\n",
        "anomalies.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tALUnU9ulEgZ"
      },
      "source": [
        "anomaly_alldata=pd.concat([train_anomaly, anomalies])\r\n",
        "fig = anomaly_alldata.plot(logy=True, figsize=(15,8), ylim=[1e-1, 1e3], color=['green','red'], title='Mahalanobis distance for anomaly detection').get_figure()\r\n",
        "fig.savefig('Mahalanobis distance for anomaly detection')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}